{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "\n",
      "html = \"\"\"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US\"><img alt=\"Creative Commons License\"\n",
      "style=\"border-width:0\" src=\"http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png\" /></a><br />\n",
      "<span xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://purl.org/dc/dcmitype/Dataset\" property=\"dct:title\" rel=\"dct:type\">\n",
      "\"python4oceanographers\"</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://ocefpaf.github.io/\"\n",
      "property=\"cc:attributionName\" rel=\"cc:attributionURL\">Filipe Fernandes</a> is licensed under a <a rel=\"license\"\n",
      "href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US\">\n",
      "Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>.<br />\n",
      "Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://ocefpaf.github.io/\"\n",
      "rel=\"dct:source\">http://ocefpaf.github.io/</a>.\"\"\"\n",
      "\n",
      "def css_styling():\n",
      "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "/*        margin-left:16% !important;\n",
        "        margin-right:auto;*/\n",
        "        margin-left:auto;\n",
        "        margin-right:16% !important;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 135%;\n",
        "        font-size: 120%;\n",
        "        width:600px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "/*    .prompt{\n",
        "        display: None;\n",
        "    }*/\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "\n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x3f29750>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<!-- PELICAN_BEGIN_SUMMARY -->\n",
      "This post is a quick example on how to use download several [hdf 4 files](http://oceandata.sci.gsfc.nasa.gov/CZCS/Mapped/Monthly/4km/chlor/) by \"scrapping\" NASA's server.\n",
      "<!-- PELICAN_END_SUMMARY -->"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manually downloading several hdf files is, most of the time, impractical.  Some time ago I helped a friend to do so with a simple python script.  This post is just a review of that script so others can modify/re-use it for other cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All we need is a `lister` class to extract the urls from the webpage, and a `hook` function to show the download progress progress."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import urllib\n",
      "import fnmatch\n",
      "from sgmllib import SGMLParser\n",
      "\n",
      "\n",
      "class URLLister(SGMLParser):\n",
      "    \"\"\"Get urls from a html dump.\n",
      "    http://stackoverflow.com/questions/9450571/\n",
      "    how-to-extract-specified-text-in-html-using-sgmlparser.\"\"\"\n",
      "    def reset(self):\n",
      "        SGMLParser.reset(self)\n",
      "        self.urls = []\n",
      "\n",
      "    def start_a(self, attrs):\n",
      "        href = [v for k, v in attrs if k == 'href']\n",
      "        if href:\n",
      "            self.urls.extend(href)\n",
      "\n",
      "\n",
      "def progress_hook(out):\n",
      "    \"\"\"Return a progress hook function, suitable for passing to\n",
      "    urllib.retrieve, that writes to the file object *out*.\"\"\"\n",
      "    def it(n, bs, ts):\n",
      "        got = n * bs\n",
      "        if ts < 0:\n",
      "            outof = ''\n",
      "        else:\n",
      "            # On the last block n*bs can exceed ts, so we clamp it\n",
      "            # to avoid awkward questions.\n",
      "            got = min(got, ts)\n",
      "            outof = '/%d [%d%%]' % (ts, 100 * got // ts)\n",
      "        out.write(\"\\r  %d%s\" % (got, outof))\n",
      "        out.flush()\n",
      "    return it"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we will download the [Mapped Monthly mean 4km CZCS data](http://oceandata.sci.gsfc.nasa.gov/CZCS/Mapped/Monthly/4km/chlor/), but this script can be extent to any webpage with a list of urls."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = \"http://oceandata.sci.gsfc.nasa.gov/CZCS/Mapped/Monthly/4km/chlor/\"\n",
      "\n",
      "# Get page html and parse urls.\n",
      "usock = urllib.urlopen(url)\n",
      "parser = URLLister()\n",
      "parser.feed(usock.read())\n",
      "usock.close()\n",
      "parser.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before downloading let's filter by the filename extension, so we download just what we really want."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get only the urls that have `bz2` files.\n",
      "filetype = \"*.bz2\"\n",
      "file_list = [filename for filename in fnmatch.filter(parser.urls, filetype)]\n",
      "\n",
      "# Download the file list.\n",
      "for url in file_list:\n",
      "    hdf_file = url.split('/')[-1]\n",
      "    sys.stdout.write(hdf_file + '\\n')\n",
      "    urllib.urlretrieve(url, filename=hdf_file,\n",
      "                       reporthook=progress_hook(sys.stdout))\n",
      "    sys.stdout.write('\\n')\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check this post at [*nbviewer*.](http://nbviewer.ipython.org/urls/raw.github.com/ocefpaf/python4oceanographers/master/content/downloads/notebooks/download_hdf.ipynb)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US\"><img alt=\"Creative Commons License\"\n",
        "style=\"border-width:0\" src=\"http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png\" /></a><br />\n",
        "<span xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://purl.org/dc/dcmitype/Dataset\" property=\"dct:title\" rel=\"dct:type\">\n",
        "\"python4oceanographers\"</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://ocefpaf.github.io/\"\n",
        "property=\"cc:attributionName\" rel=\"cc:attributionURL\">Filipe Fernandes</a> is licensed under a <a rel=\"license\"\n",
        "href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US\">\n",
        "Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>.<br />\n",
        "Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://ocefpaf.github.io/\"\n",
        "rel=\"dct:source\">http://ocefpaf.github.io/</a>."
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<IPython.core.display.HTML at 0x3f29790>"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}